<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ConstrainedKMeans &mdash; ccluster  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Clustering Euclidean Data" href="../examples/index.html" />
    <link rel="prev" title="ccluster" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ccluster
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">ConstrainedKMeans</a></li>
<li class="toctree-l1"><a class="reference internal" href="#constrainedspectralclustering">ConstrainedSpectralClustering</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Clustering Euclidean Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html#clustering-graph-data">Clustering Graph Data</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ccluster</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">ConstrainedKMeans</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="constrainedkmeans">
<h1>ConstrainedKMeans<a class="headerlink" href="#constrainedkmeans" title="Permalink to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedKMeans">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ccluster.size.</span></span><span class="sig-name descname"><span class="pre">ConstrainedKMeans</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_clusters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_sizes</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'k-means++'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">300</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ccluster.size.ConstrainedKMeans" title="Permalink to this definition"></a></dt>
<dd><p>Perform K-means clustering algorithm with cluster size constraints.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>n_clusters</strong><span class="classifier">int, default=8</span></dt><dd><p>The number of clusters to form as well as the number of
centroids to generate.</p>
</dd>
<dt><strong>cluster_sizes</strong><span class="classifier">array-like of shape (n_constraints,), default=None</span></dt><dd><p>The constraints for the cluster sizes. If <cite>None</cite>, we retrieve
the classical Lloyd algorithm. The constraints can either be
exhaustive (n_constraints == n_clusters) or partial
(n_constraints &lt; n_clusters).</p>
</dd>
<dt><strong>init</strong><span class="classifier">{‘k-means++’, ‘random’}, callable or array-like of shape             (n_clusters, n_features), default=’k-means++’</span></dt><dd><p>Method for initialization:</p>
<ul class="simple">
<li><p>‘k-means++’ : selects initial cluster centroids using sampling             based on an empirical probability distribution of the points’             contribution to the overall inertia. This technique speeds up             convergence. The algorithm implemented is “greedy k-means++”. It             differs from the vanilla k-means++ by making several trials at             each sampling step and choosing the best centroid among them.</p></li>
<li><p>‘random’: choose <cite>n_clusters</cite> observations (rows) at random from         data for the initial centroids.</p></li>
<li><p>If an array is passed, it should be of shape (n_clusters, n_features)        and gives the initial centers.</p></li>
<li><p>If a callable is passed, it should take arguments X, n_clusters and a        random state and return an initialization.</p></li>
</ul>
</dd>
<dt><strong>n_init</strong><span class="classifier">int, default=10</span></dt><dd><p>Number of times the k-means algorithm is run with different centroid
seeds. The final results will be the best output of <cite>n_init</cite> consecutive runs
in terms of inertia.</p>
</dd>
<dt><strong>max_iter</strong><span class="classifier">int, default=300</span></dt><dd><p>Maximum number of iterations of the k-means algorithm for a
single run.</p>
</dd>
<dt><strong>tol</strong><span class="classifier">float, default=1e-4</span></dt><dd><p>Relative tolerance with regards to Frobenius norm of the difference
in the cluster centers of two consecutive iterations to declare
convergence.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">int, default=0</span></dt><dd><p>Verbosity mode.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, RandomState instance or None, default=None</span></dt><dd><p>Determines random number generation for centroid initialization. Use
an int to make the randomness deterministic.</p>
</dd>
<dt><strong>copy_x</strong><span class="classifier">bool, default=True</span></dt><dd><p>When pre-computing distances it is more numerically accurate to center
the data first. If copy_x is True (default), then the original data is
not modified. If False, the original data is modified, and put back
before the function returns, but small numerical differences may be
introduced by subtracting and then adding the data mean. Note that if
the original data is not C-contiguous, a copy will be made even if
copy_x is False. If the original data is sparse, but not in CSR format,
a copy will be made even if copy_x is False.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ccluster.size</span> <span class="kn">import</span> <span class="n">ConstrainedKMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>               <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">ConstrainedKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cluster_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
<span class="go">array([1, 1, 1, 0, 0, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">array([1, 0], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
<span class="go">array([[10.  ,  3.  ],</span>
<span class="go">       [ 3.25,  1.5 ]])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>cluster_centers_</strong><span class="classifier">ndarray of shape (n_clusters, n_features)</span></dt><dd><p>Coordinates of cluster centers. If the algorithm stops before fully
converging (see <code class="docutils literal notranslate"><span class="pre">tol</span></code> and <code class="docutils literal notranslate"><span class="pre">max_iter</span></code>), these will not be
consistent with <code class="docutils literal notranslate"><span class="pre">labels_</span></code>.</p>
</dd>
<dt><strong>labels_</strong><span class="classifier">ndarray of shape (n_samples,)</span></dt><dd><p>Labels of each point</p>
</dd>
<dt><strong>inertia_</strong><span class="classifier">float</span></dt><dd><p>Sum of squared distances of samples to their closest cluster center,
weighted by the sample weights if provided.</p>
</dd>
<dt><strong>n_iter_</strong><span class="classifier">int</span></dt><dd><p>Number of iterations run.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedKMeans.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ccluster.size.ConstrainedKMeans.fit" title="Permalink to this definition"></a></dt>
<dd><p>Compute k-means clustering.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>Training instances to cluster. It must be noted that the data
will be converted to C ordering, which will cause a memory
copy if the given data is not C-contiguous.
If a sparse matrix is passed, a copy will be made if it’s not in
CSR format.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present here for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Fitted estimator.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedKMeans.fit_predict">
<span class="sig-name descname"><span class="pre">fit_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ccluster.size.ConstrainedKMeans.fit_predict" title="Permalink to this definition"></a></dt>
<dd><p>Compute cluster centers and predict cluster index for each sample.</p>
<p>Convenience method; equivalent to calling fit(X) followed by
predict(X).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>New data to transform.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present here for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>labels</strong><span class="classifier">ndarray of shape (n_samples,)</span></dt><dd><p>Index of the cluster each sample belongs to.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedKMeans.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ccluster.size.ConstrainedKMeans.fit_transform" title="Permalink to this definition"></a></dt>
<dd><p>Compute clustering and transform X to cluster-distance space.</p>
<p>Equivalent to fit(X).transform(X), but more efficiently implemented.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>New data to transform.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present here for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_new</strong><span class="classifier">ndarray of shape (n_samples, n_clusters)</span></dt><dd><p>X transformed in the new space.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedKMeans.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_sizes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ccluster.size.ConstrainedKMeans.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict the closest cluster each sample in X belongs to.</p>
<p>In the vector quantization literature, <cite>cluster_centers_</cite> is called
the code book and each value returned by <cite>predict</cite> is the index of
the closest code in the code book.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>New data to predict.</p>
</dd>
<dt><strong>cluster_sizes: ndarray of shape (n_constraints,)</strong></dt><dd><p>The number of points to assign to each constrained cluster.</p>
</dd>
<dt><strong>Returns</strong></dt><dd></dd>
<dt><strong>——-</strong></dt><dd></dd>
<dt><strong>labels</strong><span class="classifier">ndarray of shape (n_samples,)</span></dt><dd><p>Index of the cluster each sample belongs to.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedKMeans.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ccluster.size.ConstrainedKMeans.score" title="Permalink to this definition"></a></dt>
<dd><p>Opposite of the value of X on the K-means objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>New data.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present here for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p>Opposite of the value of X on the K-means objective.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedKMeans.set_predict_request">
<span class="sig-name descname"><span class="pre">set_predict_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_sizes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#ccluster.size.ConstrainedKMeans" title="ccluster.size.ckmeans.ConstrainedKMeans"><span class="pre">ConstrainedKMeans</span></a></span></span><a class="headerlink" href="#ccluster.size.ConstrainedKMeans.set_predict_request" title="Permalink to this definition"></a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config()</span></code>).
Please see <span class="xref std std-ref">User Guide</span> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">predict</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">predict</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>cluster_sizes</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">cluster_sizes</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">predict</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The updated object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedKMeans.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ccluster.size.ConstrainedKMeans.transform" title="Permalink to this definition"></a></dt>
<dd><p>Transform X to a cluster-distance space.</p>
<p>In the new space, each dimension is the distance to the cluster
centers. Note that even if X is sparse, the array returned by
<cite>transform</cite> will typically be dense.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>New data to transform.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_new</strong><span class="classifier">ndarray of shape (n_samples, n_clusters)</span></dt><dd><p>X transformed in the new space.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="constrainedspectralclustering">
<h1>ConstrainedSpectralClustering<a class="headerlink" href="#constrainedspectralclustering" title="Permalink to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedSpectralClustering">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ccluster.size.</span></span><span class="sig-name descname"><span class="pre">ConstrainedSpectralClustering</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_clusters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_sizes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eigen_solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_components</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affinity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rbf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eigen_tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">degree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coef0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ccluster.size.ConstrainedSpectralClustering" title="Permalink to this definition"></a></dt>
<dd><p>Apply clustering to a projection of the normalized Laplacian with cluster size constraints.</p>
<p>When calling <code class="docutils literal notranslate"><span class="pre">fit</span></code>, an affinity matrix is constructed using either
a kernel function such the Gaussian (aka RBF) kernel with Euclidean
distance <code class="docutils literal notranslate"><span class="pre">d(X,</span> <span class="pre">X)</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">X</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>or a k-nearest neighbors connectivity matrix.</p>
<p>Alternatively, a user-provided affinity matrix can be specified by
setting <code class="docutils literal notranslate"><span class="pre">affinity='precomputed'</span></code>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>n_clusters</strong><span class="classifier">int, default=8</span></dt><dd><p>The dimension of the projection subspace.</p>
</dd>
<dt><strong>cluster_sizes</strong><span class="classifier">array-like of shape (n_constraints,), default=None</span></dt><dd><p>The constraints for the cluster sizes. If <cite>None</cite>, we retrieve
the classical spectral clustering algorithm. The constraints can
either be exhaustive (n_constraints == n_clusters) or partial
(n_constraints &lt; n_clusters).</p>
</dd>
<dt><strong>eigen_solver</strong><span class="classifier">{‘arpack’, ‘lobpcg’, ‘amg’}, default=None</span></dt><dd><p>The eigenvalue decomposition strategy to use. AMG requires pyamg
to be installed. It can be faster on very large, sparse problems,
but may also lead to instabilities. If None, then <code class="docutils literal notranslate"><span class="pre">'arpack'</span></code> is
used.</p>
</dd>
<dt><strong>n_components</strong><span class="classifier">int, default=None</span></dt><dd><p>Number of eigenvectors to use for the spectral embedding. If None,
defaults to <cite>n_clusters</cite>.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, RandomState instance, default=None</span></dt><dd><p>A pseudo random number generator used for the initialization
of the lobpcg eigenvectors decomposition when <cite>eigen_solver ==
‘amg’</cite>, and for the K-Means initialization. Use an int to make
the results deterministic across calls.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using <cite>eigen_solver == ‘amg’</cite>,
it is necessary to also fix the global numpy seed with
<cite>np.random.seed(int)</cite> to get deterministic results. See
<a class="reference external" href="https://github.com/pyamg/pyamg/issues/139">https://github.com/pyamg/pyamg/issues/139</a> for further
information.</p>
</div>
</dd>
<dt><strong>n_init</strong><span class="classifier">int, default=10</span></dt><dd><p>Number of time the k-means algorithm will be run with different
centroid seeds. The final results will be the best output of n_init
consecutive runs in terms of inertia.</p>
</dd>
<dt><strong>gamma</strong><span class="classifier">float, default=1.0</span></dt><dd><p>Kernel coefficient for rbf, poly, sigmoid, laplacian and chi2 kernels.
Ignored for <code class="docutils literal notranslate"><span class="pre">affinity='nearest_neighbors'</span></code>.</p>
</dd>
<dt><strong>affinity</strong><span class="classifier">str or callable, default=’rbf’</span></dt><dd><dl class="simple">
<dt>How to construct the affinity matrix.</dt><dd><ul class="simple">
<li><p>‘nearest_neighbors’: construct the affinity matrix by computing a
graph of nearest neighbors.</p></li>
<li><p>‘rbf’: construct the affinity matrix using a radial basis function
(RBF) kernel.</p></li>
<li><p>‘precomputed’: interpret <code class="docutils literal notranslate"><span class="pre">X</span></code> as a precomputed affinity matrix,
where larger values indicate greater similarity between instances.</p></li>
<li><p>‘precomputed_nearest_neighbors’: interpret <code class="docutils literal notranslate"><span class="pre">X</span></code> as a sparse graph
of precomputed distances, and construct a binary affinity matrix
from the <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> nearest neighbors of each instance.</p></li>
<li><p>one of the kernels supported by
<code class="xref py py-func docutils literal notranslate"><span class="pre">pairwise_kernels()</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Only kernels that produce similarity scores (non-negative values that
increase with similarity) should be used. This property is not checked
by the clustering algorithm.</p>
</dd>
<dt><strong>n_neighbors</strong><span class="classifier">int, default=10</span></dt><dd><p>Number of neighbors to use when constructing the affinity matrix using
the nearest neighbors method. Ignored for <code class="docutils literal notranslate"><span class="pre">affinity='rbf'</span></code>.</p>
</dd>
<dt><strong>eigen_tol</strong><span class="classifier">float, default=”auto”</span></dt><dd><p>Stopping criterion for eigen decomposition of the Laplacian matrix.
If <cite>eigen_tol=”auto”</cite> then the passed tolerance will depend on the
<cite>eigen_solver</cite>:</p>
<ul class="simple">
<li><p>If <cite>eigen_solver=”arpack”</cite>, then <cite>eigen_tol=0.0</cite>;</p></li>
<li><p>If <cite>eigen_solver=”lobpcg”</cite> or <cite>eigen_solver=”amg”</cite>, then
<cite>eigen_tol=None</cite> which configures the underlying <cite>lobpcg</cite> solver to
automatically resolve the value according to their heuristics. See,
<code class="xref py py-func docutils literal notranslate"><span class="pre">scipy.sparse.linalg.lobpcg()</span></code> for details.</p></li>
</ul>
<p>Note that when using <cite>eigen_solver=”lobpcg”</cite> or <cite>eigen_solver=”amg”</cite>
values of <cite>tol&lt;1e-5</cite> may lead to convergence issues and should be
avoided.</p>
</dd>
<dt><strong>degree</strong><span class="classifier">float, default=3</span></dt><dd><p>Degree of the polynomial kernel. Ignored by other kernels.</p>
</dd>
<dt><strong>coef0</strong><span class="classifier">float, default=1</span></dt><dd><p>Zero coefficient for polynomial and sigmoid kernels.
Ignored by other kernels.</p>
</dd>
<dt><strong>kernel_params</strong><span class="classifier">dict of str to any, default=None</span></dt><dd><p>Parameters (keyword arguments) and values for kernel passed as
callable object. Ignored by other kernels.</p>
</dd>
<dt><strong>n_jobs</strong><span class="classifier">int, default=None</span></dt><dd><p>The number of parallel jobs to run when <cite>affinity=’nearest_neighbors’</cite>
or <cite>affinity=’precomputed_nearest_neighbors’</cite>. The neighbors search
will be done in parallel.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool, default=False</span></dt><dd><p>Verbosity mode.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>A distance matrix for which 0 indicates identical elements and high values
indicate very dissimilar elements can be transformed into an affinity /
similarity matrix that is well-suited for the algorithm by
applying the Gaussian (aka RBF, heat) kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="n">dist_matrix</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">delta</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">delta</span></code> is a free parameter representing the width of the Gaussian
kernel.</p>
<p>An alternative is to take a symmetric version of the k-nearest neighbors
connectivity matrix of the points.</p>
<p>If the pyamg package is installed, it is used: this greatly
speeds up computation.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ccluster.size</span> <span class="kn">import</span> <span class="n">ConstrainedSpectralClustering</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clustering</span> <span class="o">=</span> <span class="n">ConstrainedSpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cluster_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>        <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clustering</span><span class="o">.</span><span class="n">labels_</span>
<span class="go">array([0, 0, 0, 1, 0, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clustering</span>
<span class="go">ConstrainedSpectralClustering(cluster_sizes=array([4, 2]), n_clusters=2,</span>
<span class="go">    random_state=0)</span>
</pre></div>
</div>
<dl class="field-list">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>affinity_matrix_</strong><span class="classifier">array-like of shape (n_samples, n_samples)</span></dt><dd><p>Affinity matrix used for clustering. Available only after calling
<code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
<dt><strong>labels_</strong><span class="classifier">ndarray of shape (n_samples,)</span></dt><dd><p>Labels of each point</p>
</dd>
<dt><strong>n_features_in_</strong><span class="classifier">int</span></dt><dd><p>Number of features seen during <span class="xref std std-term">fit</span>.</p>
</dd>
<dt><strong>feature_names_in_</strong><span class="classifier">ndarray of shape (<cite>n_features_in_</cite>,)</span></dt><dd><p>Names of features seen during <span class="xref std std-term">fit</span>. Defined only when <cite>X</cite>
has feature names that are all strings.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedSpectralClustering.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ccluster.size.ConstrainedSpectralClustering.fit" title="Permalink to this definition"></a></dt>
<dd><p>Perform spectral clustering from features, or affinity matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples)</span></dt><dd><p>Training instances to cluster, similarities / affinities between
instances if <code class="docutils literal notranslate"><span class="pre">affinity='precomputed'</span></code>, or distances between
instances if <code class="docutils literal notranslate"><span class="pre">affinity='precomputed_nearest_neighbors</span></code>. If a
sparse matrix is provided in a format other than <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code>,
<code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code>, or <code class="docutils literal notranslate"><span class="pre">coo_matrix</span></code>, it will be converted into a
sparse <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code>.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present here for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>A fitted instance of the estimator.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ccluster.size.ConstrainedSpectralClustering.fit_predict">
<span class="sig-name descname"><span class="pre">fit_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ccluster.size.ConstrainedSpectralClustering.fit_predict" title="Permalink to this definition"></a></dt>
<dd><p>Perform constrained spectral clustering on <cite>X</cite> and return cluster labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples)</span></dt><dd><p>Training instances to cluster, similarities / affinities between
instances if <code class="docutils literal notranslate"><span class="pre">affinity='precomputed'</span></code>, or distances between
instances if <code class="docutils literal notranslate"><span class="pre">affinity='precomputed_nearest_neighbors</span></code>. If a
sparse matrix is provided in a format other than <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code>,
<code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code>, or <code class="docutils literal notranslate"><span class="pre">coo_matrix</span></code>, it will be converted into a
sparse <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code>.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present here for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>labels</strong><span class="classifier">ndarray of shape (n_samples,)</span></dt><dd><p>Cluster labels.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="ccluster" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../examples/index.html" class="btn btn-neutral float-right" title="Clustering Euclidean Data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Chakib Fettal.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>